{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0000001",
   "metadata": {},
   "source": [
    "# 2. Stereo Vision Calibration\n",
    "\n",
    "Reads the image pairs saved by `ag-cam-tools calibration-capture` from\n",
    "`stereoLeft/` and `stereoRight/`, detects checkerboard corners in each pair,\n",
    "and runs OpenCV stereo calibration.\n",
    "\n",
    "Outputs intrinsics, extrinsics, and rectification maps to `calib_result/`\n",
    "for use in `3.Depthmap_with_Tuning_Bar.ipynb`.\n",
    "\n",
    "**This notebook has no camera dependency** --- all processing is offline.\n",
    "\n",
    "---\n",
    "**Camera: Lucid PHD IMX273 --- 40 mm baseline, 3 mm FL**\n",
    "\n",
    "Image resolution is auto-detected from the captured files (supports both\n",
    "full resolution 1440x1080 and 2:1 binned 720x540).\n",
    "\n",
    "The baseline distance is not set here; it is computed from the calibration\n",
    "images and stored in the exported extrinsics (translation vector `T`).\n",
    "\n",
    "### Setup (one-time)\n",
    "```bash\n",
    "cd calibration\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "python -m ipykernel install --user --name agrippa-calibration --display-name \"agrippa-calibration\"\n",
    "```\n",
    "\n",
    "Then select the **agrippa-calibration** kernel in Jupyter before running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000002",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000005",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "If you used a different checkerboard, update `rows`, `columns`, and\n",
    "`square_size` to match.\n",
    "\n",
    "Image size is auto-detected from the first loaded image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000006",
   "metadata": {},
   "outputs": [],
   "source": "# Checkerboard inner-corner count and physical square size (cm).\n# Inner corners = squares - 1 in each dimension.\n# For an 18x25 square board, inner corners are 17x24.\nrows        = 17\ncolumns     = 24\nsquare_size = 0.75  # cm\n\n# 3D object points for one board view (Z=0 plane).\nobjp = np.zeros((rows * columns, 3), np.float32)\nobjp[:, :2] = np.indices((rows, columns)).T.reshape(-1, 2)\nobjp *= square_size\n\n# Subpixel refinement criteria.\ncorner_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 30, 0.01)"
  },
  {
   "cell_type": "code",
   "id": "h4wd9o49ykc",
   "source": "import ipywidgets as widgets\nfrom IPython.display import display\n\n# Scan for calibration session folders (contain stereoLeft/).\n_sessions = sorted(\n    [d for d in os.listdir(\".\")\n     if os.path.isdir(d) and d.startswith(\"calibration_\")\n     and os.path.isdir(os.path.join(d, \"stereoLeft\"))],\n    reverse=True,  # most recent first\n)\n\nif not _sessions:\n    raise FileNotFoundError(\n        \"No calibration session folders found in the current directory.\\n\"\n        \"Run `ag-cam-tools calibration-capture` first.\"\n    )\n\n_session_dropdown = widgets.Dropdown(\n    options=_sessions,\n    value=_sessions[0],\n    description=\"Session:\",\n    layout=widgets.Layout(width=\"500px\"),\n    style={\"description_width\": \"80px\"},\n)\n\n# Count images in each session for the info label.\ndef _session_info(name):\n    n = len(glob.glob(os.path.join(name, \"stereoLeft\", \"*.png\")))\n    has_calib = os.path.isdir(os.path.join(name, \"calib_result\"))\n    status = \" (calibrated)\" if has_calib else \"\"\n    return f\"{n} image pairs{status}\"\n\n_info_label = widgets.Label(value=_session_info(_sessions[0]))\n\ndef _on_change(change):\n    _info_label.value = _session_info(change[\"new\"])\n\n_session_dropdown.observe(_on_change, names=\"value\")\ndisplay(widgets.HBox([_session_dropdown, _info_label]))\n\n# Downstream cells read from this variable.\nsession_path = _session_dropdown.value",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b0000007",
   "metadata": {},
   "source": [
    "## Corner detection pass\n",
    "\n",
    "Each image pair is loaded, then OpenCV searches for checkerboard corners\n",
    "with subpixel refinement. Pairs where the board is not fully visible in\n",
    "both frames are automatically discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000008",
   "metadata": {},
   "outputs": [],
   "source": "object_points     = []\nimage_points_left = []\nimage_points_right = []\naccepted = 0\ndiscarded = 0\n\n# Read the current dropdown selection (in case it changed since the picker cell ran).\nsession_path = _session_dropdown.value\n\n# Resolve session path and create calib_result inside it.\nsession_abs = os.path.abspath(session_path)\ncalib_result_path = os.path.join(session_abs, \"calib_result\")\nos.makedirs(calib_result_path, exist_ok=True)\n\nleft_glob  = os.path.join(session_abs, \"stereoLeft\",  \"*.png\")\nright_glob = os.path.join(session_abs, \"stereoRight\", \"*.png\")\n\nimages_left  = sorted(glob.glob(left_glob))\nimages_right = sorted(glob.glob(right_glob))\n\nif not images_left:\n    raise FileNotFoundError(\n        f\"No images found in {left_glob}. \"\n        \"Run `ag-cam-tools calibration-capture` first, then set session_path above.\"\n    )\n\n# Auto-detect image size from the first image.\nfirst_img = cv2.imread(images_left[0])\nimage_size = (first_img.shape[1], first_img.shape[0])  # (width, height)\n\nprint(f\"Session:    {session_abs}\")\nprint(f\"Found {len(images_left)} left / {len(images_right)} right images.\")\nprint(f\"Image size: {image_size[0]} x {image_size[1]}\")\nprint(\"Starting corner detection...\\n\")\n\nfor img_left_path, img_right_path in zip(images_left, images_right):\n    print(f\"Pair {accepted + discarded:03d}  {os.path.basename(img_left_path)}\")\n\n    img_left  = cv2.imread(img_left_path,  cv2.IMREAD_UNCHANGED)\n    img_right = cv2.imread(img_right_path, cv2.IMREAD_UNCHANGED)\n\n    # Ensure both images are BGR.\n    if img_left.ndim == 2:\n        img_left  = cv2.cvtColor(img_left,  cv2.COLOR_GRAY2BGR)\n        img_right = cv2.cvtColor(img_right, cv2.COLOR_GRAY2BGR)\n\n    img_left  = cv2.resize(img_left,  image_size)\n    img_right = cv2.resize(img_right, image_size)\n\n    # Detect corners in both images.\n    gray_l = cv2.cvtColor(img_left,  cv2.COLOR_BGR2GRAY)\n    gray_r = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n\n    ret_l, corners_l = cv2.findChessboardCorners(gray_l, (rows, columns))\n    ret_r, corners_r = cv2.findChessboardCorners(gray_r, (rows, columns))\n\n    if not ret_l or not ret_r:\n        reason = \"left\" if not ret_l else \"right\"\n        if not ret_l and not ret_r:\n            reason = \"both\"\n        print(f\"  -> discarded: chessboard not found in {reason}\")\n        discarded += 1\n        continue\n\n    # Subpixel refinement.\n    cv2.cornerSubPix(gray_l, corners_l, (11, 11), (-1, -1), corner_criteria)\n    cv2.cornerSubPix(gray_r, corners_r, (11, 11), (-1, -1), corner_criteria)\n\n    object_points.append(objp)\n    image_points_left.append(corners_l.reshape(-1, 2))\n    image_points_right.append(corners_r.reshape(-1, 2))\n    accepted += 1\n\nprint(f\"\\nDone. {accepted} pairs accepted, {discarded} discarded.\")"
  },
  {
   "cell_type": "markdown",
   "id": "b1w3s76up64",
   "source": "## Per-camera intrinsic calibration\n\nRun `cv2.calibrateCamera` independently on each camera before the joint\nstereo solve.  This gives per-camera RMS reprojection errors (useful for\nspotting a bad lens or dataset) and provides a good initial guess for the\nmore constrained `cv2.stereoCalibrate` that follows.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "551774g7apd",
   "source": "calib_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)\nmono_flags = (cv2.CALIB_FIX_ASPECT_RATIO |\n              cv2.CALIB_ZERO_TANGENT_DIST |\n              cv2.CALIB_RATIONAL_MODEL)\n\nrms_l, cam_mat_l_init, dist_l_init, _, _ = cv2.calibrateCamera(\n    object_points, image_points_left, image_size,\n    cameraMatrix=None, distCoeffs=None,\n    criteria=calib_criteria, flags=mono_flags)\n\nrms_r, cam_mat_r_init, dist_r_init, _, _ = cv2.calibrateCamera(\n    object_points, image_points_right, image_size,\n    cameraMatrix=None, distCoeffs=None,\n    criteria=calib_criteria, flags=mono_flags)\n\nprint(f\"Left  camera RMS: {rms_l:.4f} px\")\nprint(f\"Right camera RMS: {rms_r:.4f} px\")\nprint(f\"Left  focal length: fx={cam_mat_l_init[0,0]:.1f}  fy={cam_mat_l_init[1,1]:.1f} px\")\nprint(f\"Right focal length: fx={cam_mat_r_init[0,0]:.1f}  fy={cam_mat_r_init[1,1]:.1f} px\")\n\nif abs(rms_l - rms_r) > 0.3:\n    print(f\"\\n  Warning: large RMS difference between cameras ({abs(rms_l - rms_r):.2f} px).\")\n    print(\"  Check for focus mismatch or a damaged lens.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b0000009",
   "metadata": {},
   "source": "## Stereo calibration\n\nRuns `cv2.stereoCalibrate` seeded with the per-camera intrinsics estimated\nabove (`CALIB_USE_INTRINSIC_GUESS`).  This constrains the joint solver and\nimproves convergence, especially with the 8-parameter rational distortion\nmodel.\n\nA reprojection error below **0.5 px** indicates a good calibration.\n\n> **Distortion model:** the Edmund Optics #20-061 lens has 34.78% barrel\n> distortion at full field. The rational model (`cv2.CALIB_RATIONAL_MODEL`)\n> is used below, which fits an 8-coefficient distortion model instead of the\n> default 5. This better captures the heavy radial distortion of these\n> wide-angle lenses."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000010",
   "metadata": {},
   "outputs": [],
   "source": "print(\"Starting stereo calibration...\")\n\nstereo_flags = (cv2.CALIB_FIX_ASPECT_RATIO |\n                cv2.CALIB_ZERO_TANGENT_DIST |\n                cv2.CALIB_SAME_FOCAL_LENGTH |\n                cv2.CALIB_RATIONAL_MODEL |\n                cv2.CALIB_USE_INTRINSIC_GUESS)\n\nrms, cam_mat_l, dist_l, cam_mat_r, dist_r, R, T, E, F = cv2.stereoCalibrate(\n    object_points,\n    image_points_left,\n    image_points_right,\n    cameraMatrix1=cam_mat_l_init.copy(), distCoeffs1=dist_l_init.copy(),\n    cameraMatrix2=cam_mat_r_init.copy(), distCoeffs2=dist_r_init.copy(),\n    imageSize=image_size,\n    criteria=calib_criteria,\n    flags=stereo_flags)\n\nprint(f\"Stereo RMS reprojection error: {rms:.4f} px\")\nprint(f\"Distortion coefficients: {dist_l.shape[1]} parameters (rational model)\")\nprint(f\"Baseline (||T||): {np.linalg.norm(T):.2f} cm\")\nif rms > 0.5:\n    print(\"\\n  Warning: error > 0.5 px — consider re-capturing images from more angles.\")\nelse:\n    print(\"  Error within acceptable range.\")"
  },
  {
   "cell_type": "markdown",
   "id": "6vaeewp3pnm",
   "source": "## Per-pair reprojection error analysis\n\nProject each pair's object points through the stereo model and measure the\nreprojection error.  Pairs with RMS significantly above the median are\nlikely bad captures (motion blur, partial occlusion, pattern flex).\n\nIf outliers are flagged, the next cell removes them — then re-run the\n**Per-camera intrinsic calibration** and **Stereo calibration** cells above\nto get a cleaner result.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "iaksyuwlx1f",
   "source": "import matplotlib.pyplot as plt\n\n# Re-derive per-image poses via solvePnP on the left camera (reference frame),\n# then transform to the right camera using R, T from stereoCalibrate.\nper_pair_rms_l = []\nper_pair_rms_r = []\nfor i in range(len(object_points)):\n    pts_3d = object_points[i]\n    pts_2d_l = image_points_left[i]\n    pts_2d_r = image_points_right[i]\n\n    _, rvec_l, tvec_l = cv2.solvePnP(pts_3d, pts_2d_l, cam_mat_l, dist_l)\n\n    # Right camera pose = R @ left_pose + T.\n    rvec_r, _ = cv2.Rodrigues(R @ cv2.Rodrigues(rvec_l)[0])\n    tvec_r = R @ tvec_l + T\n\n    proj_l, _ = cv2.projectPoints(pts_3d, rvec_l, tvec_l, cam_mat_l, dist_l)\n    proj_r, _ = cv2.projectPoints(pts_3d, rvec_r, tvec_r, cam_mat_r, dist_r)\n\n    err_l = np.linalg.norm(pts_2d_l - proj_l.reshape(-1, 2), axis=1)\n    err_r = np.linalg.norm(pts_2d_r - proj_r.reshape(-1, 2), axis=1)\n\n    per_pair_rms_l.append(np.sqrt(np.mean(err_l**2)))\n    per_pair_rms_r.append(np.sqrt(np.mean(err_r**2)))\n\nper_pair_rms_l = np.array(per_pair_rms_l)\nper_pair_rms_r = np.array(per_pair_rms_r)\nper_pair_rms_combined = np.sqrt((per_pair_rms_l**2 + per_pair_rms_r**2) / 2)\n\nmedian_rms = np.median(per_pair_rms_combined)\noutlier_threshold = max(2.0 * median_rms, 1.0)  # at least 1.0 px\noutlier_mask = per_pair_rms_combined > outlier_threshold\n\n# Print table.\nprint(f\"{'Pair':>4}  {'Left RMS':>9}  {'Right RMS':>10}  {'Combined':>9}  {'Status'}\")\nprint(\"-\" * 55)\nfor i in range(len(per_pair_rms_combined)):\n    flag = \" ** OUTLIER **\" if outlier_mask[i] else \"\"\n    print(f\"{i:4d}  {per_pair_rms_l[i]:9.3f}  {per_pair_rms_r[i]:10.3f}  \"\n          f\"{per_pair_rms_combined[i]:9.3f}{flag}\")\n\nn_outliers = int(outlier_mask.sum())\nprint(f\"\\nMedian RMS: {median_rms:.3f} px | Outlier threshold: {outlier_threshold:.3f} px\")\nprint(f\"Outliers: {n_outliers} / {len(per_pair_rms_combined)}\")\n\n# Bar chart.\nfig, ax = plt.subplots(figsize=(max(8, len(per_pair_rms_combined) * 0.4), 4))\ncolors = [\"tab:red\" if m else \"tab:blue\" for m in outlier_mask]\nax.bar(range(len(per_pair_rms_combined)), per_pair_rms_combined, color=colors)\nax.axhline(y=outlier_threshold, color=\"red\", linestyle=\"--\", linewidth=0.8,\n           label=f\"threshold ({outlier_threshold:.2f} px)\")\nax.axhline(y=median_rms, color=\"gray\", linestyle=\":\", linewidth=0.8,\n           label=f\"median ({median_rms:.2f} px)\")\nax.set_xlabel(\"Image pair index\")\nax.set_ylabel(\"RMS reprojection error (px)\")\nax.set_title(\"Per-pair reprojection error\")\nax.legend()\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "16p435nf0ny",
   "source": "# Remove outlier pairs from the point lists.\n# After running this cell, re-run \"Per-camera intrinsic calibration\" and\n# \"Stereo calibration\" above to recalibrate without the bad pairs.\n\nif n_outliers == 0:\n    print(\"No outliers detected — nothing to remove.\")\nelse:\n    keep = ~outlier_mask\n    object_points     = [object_points[i]     for i in range(len(keep)) if keep[i]]\n    image_points_left = [image_points_left[i]  for i in range(len(keep)) if keep[i]]\n    image_points_right = [image_points_right[i] for i in range(len(keep)) if keep[i]]\n    print(f\"Removed {n_outliers} outlier pair(s). {len(object_points)} pairs remain.\")\n    print(\"Re-run the Per-camera intrinsic calibration and Stereo calibration cells above.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a0sz0220nl",
   "source": "## Stereo rectification and export\n\nCompute rectification transforms, undistortion/rectification maps, and\nexport all calibration artifacts as `.npy` files to `calib_result/`.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "92arb3o0a4d",
   "source": "# Read the current dropdown selection (in case it changed since the picker cell ran).\nsession_path = _session_dropdown.value\nsession_abs = os.path.abspath(session_path)\ncalib_result_path = os.path.join(session_abs, \"calib_result\")\nos.makedirs(calib_result_path, exist_ok=True)\n\n# Stereo rectification.\nR1, R2, P1, P2, Q, valid_roi_l, valid_roi_r = cv2.stereoRectify(\n    cam_mat_l, dist_l,\n    cam_mat_r, dist_r,\n    image_size, R, T,\n    flags=0)\n\n# Compute undistortion + rectification maps.\nmap_l1, map_l2 = cv2.initUndistortRectifyMap(\n    cam_mat_l, dist_l, R1, P1, image_size, cv2.CV_32FC1)\nmap_r1, map_r2 = cv2.initUndistortRectifyMap(\n    cam_mat_r, dist_r, R2, P2, image_size, cv2.CV_32FC1)\n\n# Export all calibration results as .npy files (compatible with notebook 3).\nnp.save(os.path.join(calib_result_path, \"cam_mats_left.npy\"),           cam_mat_l)\nnp.save(os.path.join(calib_result_path, \"cam_mats_right.npy\"),          cam_mat_r)\nnp.save(os.path.join(calib_result_path, \"dist_coefs_left.npy\"),         dist_l)\nnp.save(os.path.join(calib_result_path, \"dist_coefs_right.npy\"),        dist_r)\nnp.save(os.path.join(calib_result_path, \"rot_mat.npy\"),                 R)\nnp.save(os.path.join(calib_result_path, \"trans_vec.npy\"),               T)\nnp.save(os.path.join(calib_result_path, \"e_mat.npy\"),                   E)\nnp.save(os.path.join(calib_result_path, \"f_mat.npy\"),                   F)\nnp.save(os.path.join(calib_result_path, \"rect_trans_left.npy\"),         R1)\nnp.save(os.path.join(calib_result_path, \"rect_trans_right.npy\"),        R2)\nnp.save(os.path.join(calib_result_path, \"proj_mats_left.npy\"),          P1)\nnp.save(os.path.join(calib_result_path, \"proj_mats_right.npy\"),         P2)\nnp.save(os.path.join(calib_result_path, \"disp_to_depth_mat.npy\"),       Q)\nnp.save(os.path.join(calib_result_path, \"valid_boxes_left.npy\"),        np.array(valid_roi_l))\nnp.save(os.path.join(calib_result_path, \"valid_boxes_right.npy\"),       np.array(valid_roi_r))\nnp.save(os.path.join(calib_result_path, \"undistortion_map_left.npy\"),   map_l1)\nnp.save(os.path.join(calib_result_path, \"undistortion_map_right.npy\"),  map_r1)\nnp.save(os.path.join(calib_result_path, \"rectification_map_left.npy\"),  map_l2)\nnp.save(os.path.join(calib_result_path, \"rectification_map_right.npy\"), map_r2)\n\nprint(f\"Calibration exported to {calib_result_path}/ ({len(os.listdir(calib_result_path))} files)\")\nprint(f\"Rectified focal length: {P1[0,0]:.1f} px\")\nprint(f\"Baseline (||T||): {np.linalg.norm(T):.2f} cm\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "h0kgzusve65",
   "source": "## Rectification quality — epipolar error\n\nThe key invariant for stereo disparity: after rectification, corresponding\npoints must lie on the **same horizontal scanline** in both images.\n\nThis cell undistorts and rectifies every detected corner pair, then\nmeasures the absolute y-difference.  A mean epipolar error below **0.5 px**\nis needed for reliable disparity matching; above **1.0 px** will cause\nvisible artefacts.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "wcme9z2upl9",
   "source": "all_y_errors = []\n\nfor i in range(len(object_points)):\n    pts_l = image_points_left[i].reshape(-1, 1, 2).astype(np.float64)\n    pts_r = image_points_right[i].reshape(-1, 1, 2).astype(np.float64)\n\n    # Undistort + rectify corner positions.\n    rect_l = cv2.undistortPoints(pts_l, cam_mat_l, dist_l, R=R1, P=P1)\n    rect_r = cv2.undistortPoints(pts_r, cam_mat_r, dist_r, R=R2, P=P2)\n\n    y_err = np.abs(rect_l[:, 0, 1] - rect_r[:, 0, 1])\n    all_y_errors.append(y_err)\n\nall_y_errors = np.concatenate(all_y_errors)\n\nmean_epipolar = np.mean(all_y_errors)\nmax_epipolar = np.max(all_y_errors)\nstd_epipolar = np.std(all_y_errors)\n\nprint(f\"Epipolar error (y-difference after rectification):\")\nprint(f\"  Mean: {mean_epipolar:.3f} px\")\nprint(f\"  Max:  {max_epipolar:.3f} px\")\nprint(f\"  Std:  {std_epipolar:.3f} px\")\nprint(f\"  Points measured: {len(all_y_errors)}\")\n\nif mean_epipolar > 1.0:\n    print(\"\\n  FAIL: mean epipolar error > 1.0 px — disparity will be unreliable.\")\n    print(\"  Re-capture calibration images or investigate outliers above.\")\nelif mean_epipolar > 0.5:\n    print(\"\\n  Warning: mean epipolar error > 0.5 px — disparity quality may suffer.\")\nelse:\n    print(\"\\n  Rectification quality is good for disparity matching.\")\n\n# Histogram.\nfig, ax = plt.subplots(figsize=(8, 3))\nax.hist(all_y_errors, bins=50, edgecolor=\"black\", linewidth=0.3)\nax.axvline(x=mean_epipolar, color=\"red\", linestyle=\"--\", linewidth=1,\n           label=f\"mean ({mean_epipolar:.3f} px)\")\nax.axvline(x=0.5, color=\"orange\", linestyle=\":\", linewidth=1, label=\"0.5 px target\")\nax.set_xlabel(\"Absolute y-error (px)\")\nax.set_ylabel(\"Count\")\nax.set_title(\"Epipolar error distribution (all rectified corners)\")\nax.legend()\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "vcbg0orwud",
   "source": "## Export C-ready remap tables\n\nConverts the float32 rectification maps into pre-computed pixel-offset\nlookup tables that `ag-cam-tools stream --rectify` can load directly.\n\nEach `.bin` file contains a 16-byte header (`RMAP` magic + width + height +\nflags) followed by `width × height` uint32 offsets — the linear source\npixel index for each destination pixel, or `0xFFFFFFFF` for out-of-bounds.\n\nThis makes the C remap a single indexed read per pixel with no float math.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "yi4qquef6og",
   "source": "def _write_remap_bin(path, width, height, map1_f32, map2_f32):\n    \"\"\"Export a pre-computed pixel-offset table for the C remap loader.\n\n    map1_f32 and map2_f32 are the (x, y) coordinate maps from\n    cv2.initUndistortRectifyMap with CV_32FC1.\n    \"\"\"\n    src_x = np.round(map1_f32).astype(np.int32)\n    src_y = np.round(map2_f32).astype(np.int32)\n    valid = (src_x >= 0) & (src_x < width) & (src_y >= 0) & (src_y < height)\n    offsets = np.where(valid, src_y * width + src_x, 0xFFFFFFFF).astype(np.uint32)\n\n    with open(path, \"wb\") as f:\n        f.write(b\"RMAP\")\n        np.array([width, height, 0], dtype=np.uint32).tofile(f)\n        offsets.tofile(f)\n\n    size_mb = os.path.getsize(path) / (1024 * 1024)\n    print(f\"  {os.path.basename(path)}: {width}x{height}, {size_mb:.1f} MB\")\n\nlbin = os.path.join(calib_result_path, \"remap_left.bin\")\nrbin = os.path.join(calib_result_path, \"remap_right.bin\")\n\nprint(\"Exporting C-ready remap tables:\")\n_write_remap_bin(lbin, image_size[0], image_size[1], map_l1, map_l2)\n_write_remap_bin(rbin, image_size[0], image_size[1], map_r1, map_r2)\nprint(f\"\\nUse with: ag-cam-tools stream --rectify {session_path}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b0000011",
   "metadata": {},
   "source": "## Inspect rectified output\n\nVisual sanity check — apply the rectification maps to the last image pair.\nCorresponding points should fall on the same horizontal scanline in both\nrectified images.  The quantitative epipolar error measured above should\nconfirm this; this plot is a quick eyeball check."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000012",
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\nrect_left  = cv2.remap(img_left,  map_l1, map_l2, cv2.INTER_LINEAR)\nrect_right = cv2.remap(img_right, map_r1, map_r2, cv2.INTER_LINEAR)\n\nunrectified = np.hstack((\n    cv2.cvtColor(img_left,  cv2.COLOR_BGR2RGB),\n    cv2.cvtColor(img_right, cv2.COLOR_BGR2RGB),\n))\nrectified = np.hstack((\n    cv2.cvtColor(rect_left,  cv2.COLOR_BGR2RGB),\n    cv2.cvtColor(rect_right, cv2.COLOR_BGR2RGB),\n))\n\nfig, axes = plt.subplots(2, 1, figsize=(16, 12))\n\nfor ax, img, title in [\n    (axes[0], unrectified, \"Original stereo pair (left | right)\"),\n    (axes[1], rectified,   \"Rectified stereo pair (left | right)\"),\n]:\n    ax.imshow(img)\n    h = img.shape[0]\n    for y in range(0, h, h // 16):\n        ax.axhline(y=y, color=\"lime\", linewidth=0.5, alpha=0.6)\n    ax.set_title(title)\n    ax.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Open 3.Depthmap_with_Tuning_Bar.ipynb to continue.\")"
  },
  {
   "cell_type": "markdown",
   "id": "s4nd6kk1swe",
   "source": "## Disparity range estimation\n\nFor classical stereo matchers (StereoBM, StereoSGBM) you must set\n`numDisparities` and `minDisparity`.  These depend on the baseline, focal\nlength, and working distance range.\n\nSet `z_near` and `z_far` below to your expected operating range (same units\nas `square_size` — cm by default), and this cell will compute the\nrecommended matcher parameters.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "t7sv5zmbuf",
   "source": "# Working distance range (same units as square_size, i.e. cm).\nz_near = 30    # closest expected object distance\nz_far  = 200   # farthest expected object distance\n\nf_px = P1[0, 0]                    # rectified focal length in pixels\nbaseline = np.linalg.norm(T)       # baseline in cm (same units as square_size)\n\nd_max = f_px * baseline / z_near   # disparity at near plane\nd_min = f_px * baseline / z_far    # disparity at far plane\n\n# numDisparities must be a multiple of 16 and cover d_max.\nnum_disp = int(np.ceil(d_max / 16) * 16)\nmin_disp = max(0, int(np.floor(d_min)))\n\nprint(f\"Rectified focal length : {f_px:.1f} px\")\nprint(f\"Baseline               : {baseline:.2f} cm\")\nprint(f\"Working range          : {z_near}–{z_far} cm\")\nprint()\nprint(f\"Disparity at z_near={z_near} cm : {d_max:.1f} px\")\nprint(f\"Disparity at z_far={z_far} cm  : {d_min:.1f} px\")\nprint()\nprint(f\"Recommended StereoBM / StereoSGBM parameters:\")\nprint(f\"  minDisparity    = {min_disp}\")\nprint(f\"  numDisparities  = {num_disp}\")\nprint()\nprint(f\"Depth resolution at z_far ({z_far} cm): \"\n      f\"{baseline * f_px / (d_min + 1)**2:.2f} cm/disparity-step\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ny2t8dvjkig",
   "source": "## Export calibration metadata\n\nWrite a machine-readable JSON summary of the calibration session.\nDownstream tools can read this instead of loading individual `.npy` files\nto get key parameters (baseline, focal length, image size, error metrics).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "t6ereldrcge",
   "source": "import json\n\nmeta = {\n    \"image_size\": list(image_size),\n    \"num_pairs_used\": len(object_points),\n    \"checkerboard\": {\n        \"rows\": rows,\n        \"columns\": columns,\n        \"square_size_cm\": square_size,\n    },\n    \"distortion_model\": \"rational_8\",\n    \"rms_stereo_px\": round(float(rms), 4),\n    \"rms_left_px\": round(float(rms_l), 4),\n    \"rms_right_px\": round(float(rms_r), 4),\n    \"per_pair_rms_px\": [round(float(v), 4) for v in per_pair_rms_combined],\n    \"mean_epipolar_error_px\": round(float(mean_epipolar), 4),\n    \"max_epipolar_error_px\": round(float(max_epipolar), 4),\n    \"baseline_cm\": round(float(np.linalg.norm(T)), 4),\n    \"focal_length_px\": round(float(P1[0, 0]), 2),\n    \"principal_point_px\": [round(float(P1[0, 2]), 2), round(float(P1[1, 2]), 2)],\n    \"disparity_range\": {\n        \"z_near_cm\": z_near,\n        \"z_far_cm\": z_far,\n        \"min_disparity\": min_disp,\n        \"num_disparities\": num_disp,\n    },\n}\n\nmeta_path = os.path.join(calib_result_path, \"calibration_meta.json\")\nwith open(meta_path, \"w\") as f:\n    json.dump(meta, f, indent=2)\n\nprint(f\"Metadata written to {meta_path}\")\nprint(json.dumps(meta, indent=2))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agrippa-calibration",
   "language": "python",
   "name": "agrippa-calibration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}