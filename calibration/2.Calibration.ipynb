{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0000001",
   "metadata": {},
   "source": [
    "# 2. Stereo Vision Calibration\n",
    "\n",
    "Reads the image pairs saved by `ag-cam-tools calibration-capture` from\n",
    "`stereoLeft/` and `stereoRight/`, detects checkerboard corners in each pair,\n",
    "and runs OpenCV stereo calibration.\n",
    "\n",
    "Outputs intrinsics, extrinsics, and rectification maps to `calib_result/`\n",
    "for use in `3.Depthmap_with_Tuning_Bar.ipynb`.\n",
    "\n",
    "**This notebook has no camera dependency** --- all processing is offline.\n",
    "\n",
    "---\n",
    "**Camera: Lucid PHD IMX273 --- 40 mm baseline, 3 mm FL**\n",
    "\n",
    "Image resolution is auto-detected from the captured files (supports both\n",
    "full resolution 1440x1080 and 2:1 binned 720x540).\n",
    "\n",
    "The baseline distance is not set here; it is computed from the calibration\n",
    "images and stored in the exported extrinsics (translation vector `T`).\n",
    "\n",
    "### Setup (one-time)\n",
    "```bash\n",
    "cd calibration\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "python -m ipykernel install --user --name agrippa-calibration --display-name \"agrippa-calibration\"\n",
    "```\n",
    "\n",
    "Then select the **agrippa-calibration** kernel in Jupyter before running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000002",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000005",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "If you used a different checkerboard, update `rows`, `columns`, and\n",
    "`square_size` to match.\n",
    "\n",
    "Image size is auto-detected from the first loaded image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000006",
   "metadata": {},
   "outputs": [],
   "source": "# Checkerboard inner-corner count and physical square size (cm).\n# Inner corners = squares - 1 in each dimension.\n# For an 18x25 square board, inner corners are 17x24.\nrows        = 17\ncolumns     = 24\nsquare_size = 0.75  # cm\n\n# 3D object points for one board view (Z=0 plane).\nobjp = np.zeros((rows * columns, 3), np.float32)\nobjp[:, :2] = np.indices((rows, columns)).T.reshape(-1, 2)\nobjp *= square_size\n\n# Subpixel refinement criteria.\ncorner_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 30, 0.01)"
  },
  {
   "cell_type": "code",
   "id": "h4wd9o49ykc",
   "source": "import ipywidgets as widgets\nfrom IPython.display import display\n\n# Scan for calibration session folders (contain stereoLeft/).\n_sessions = sorted(\n    [d for d in os.listdir(\".\")\n     if os.path.isdir(d) and d.startswith(\"calibration_\")\n     and os.path.isdir(os.path.join(d, \"stereoLeft\"))],\n    reverse=True,  # most recent first\n)\n\nif not _sessions:\n    raise FileNotFoundError(\n        \"No calibration session folders found in the current directory.\\n\"\n        \"Run `ag-cam-tools calibration-capture` first.\"\n    )\n\n_session_dropdown = widgets.Dropdown(\n    options=_sessions,\n    value=_sessions[0],\n    description=\"Session:\",\n    layout=widgets.Layout(width=\"500px\"),\n    style={\"description_width\": \"80px\"},\n)\n\n# Count images in each session for the info label.\ndef _session_info(name):\n    n = len(glob.glob(os.path.join(name, \"stereoLeft\", \"*.png\")))\n    has_calib = os.path.isdir(os.path.join(name, \"calib_result\"))\n    status = \" (calibrated)\" if has_calib else \"\"\n    return f\"{n} image pairs{status}\"\n\n_info_label = widgets.Label(value=_session_info(_sessions[0]))\n\ndef _on_change(change):\n    _info_label.value = _session_info(change[\"new\"])\n\n_session_dropdown.observe(_on_change, names=\"value\")\ndisplay(widgets.HBox([_session_dropdown, _info_label]))\n\n# Downstream cells read from this variable.\nsession_path = _session_dropdown.value",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b0000007",
   "metadata": {},
   "source": [
    "## Corner detection pass\n",
    "\n",
    "Each image pair is loaded, then OpenCV searches for checkerboard corners\n",
    "with subpixel refinement. Pairs where the board is not fully visible in\n",
    "both frames are automatically discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000008",
   "metadata": {},
   "outputs": [],
   "source": "object_points     = []\nimage_points_left = []\nimage_points_right = []\naccepted = 0\ndiscarded = 0\n\n# Read the current dropdown selection (in case it changed since the picker cell ran).\nsession_path = _session_dropdown.value\n\n# Resolve session path and create calib_result inside it.\nsession_abs = os.path.abspath(session_path)\ncalib_result_path = os.path.join(session_abs, \"calib_result\")\nos.makedirs(calib_result_path, exist_ok=True)\n\nleft_glob  = os.path.join(session_abs, \"stereoLeft\",  \"*.png\")\nright_glob = os.path.join(session_abs, \"stereoRight\", \"*.png\")\n\nimages_left  = sorted(glob.glob(left_glob))\nimages_right = sorted(glob.glob(right_glob))\n\nif not images_left:\n    raise FileNotFoundError(\n        f\"No images found in {left_glob}. \"\n        \"Run `ag-cam-tools calibration-capture` first, then set session_path above.\"\n    )\n\n# Auto-detect image size from the first image.\nfirst_img = cv2.imread(images_left[0])\nimage_size = (first_img.shape[1], first_img.shape[0])  # (width, height)\n\nprint(f\"Session:    {session_abs}\")\nprint(f\"Found {len(images_left)} left / {len(images_right)} right images.\")\nprint(f\"Image size: {image_size[0]} x {image_size[1]}\")\nprint(\"Starting corner detection...\\n\")\n\nfor img_left_path, img_right_path in zip(images_left, images_right):\n    print(f\"Pair {accepted + discarded:03d}  {os.path.basename(img_left_path)}\")\n\n    img_left  = cv2.imread(img_left_path,  cv2.IMREAD_UNCHANGED)\n    img_right = cv2.imread(img_right_path, cv2.IMREAD_UNCHANGED)\n\n    # Ensure both images are BGR.\n    if img_left.ndim == 2:\n        img_left  = cv2.cvtColor(img_left,  cv2.COLOR_GRAY2BGR)\n        img_right = cv2.cvtColor(img_right, cv2.COLOR_GRAY2BGR)\n\n    img_left  = cv2.resize(img_left,  image_size)\n    img_right = cv2.resize(img_right, image_size)\n\n    # Detect corners in both images.\n    gray_l = cv2.cvtColor(img_left,  cv2.COLOR_BGR2GRAY)\n    gray_r = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n\n    ret_l, corners_l = cv2.findChessboardCorners(gray_l, (rows, columns))\n    ret_r, corners_r = cv2.findChessboardCorners(gray_r, (rows, columns))\n\n    if not ret_l or not ret_r:\n        reason = \"left\" if not ret_l else \"right\"\n        if not ret_l and not ret_r:\n            reason = \"both\"\n        print(f\"  -> discarded: chessboard not found in {reason}\")\n        discarded += 1\n        continue\n\n    # Subpixel refinement.\n    cv2.cornerSubPix(gray_l, corners_l, (11, 11), (-1, -1), corner_criteria)\n    cv2.cornerSubPix(gray_r, corners_r, (11, 11), (-1, -1), corner_criteria)\n\n    object_points.append(objp)\n    image_points_left.append(corners_l.reshape(-1, 2))\n    image_points_right.append(corners_r.reshape(-1, 2))\n    accepted += 1\n\nprint(f\"\\nDone. {accepted} pairs accepted, {discarded} discarded.\")"
  },
  {
   "cell_type": "markdown",
   "id": "b0000009",
   "metadata": {},
   "source": "## Stereo calibration\n\nRuns `cv2.stereoCalibrate`, then `cv2.stereoRectify` and\n`cv2.initUndistortRectifyMap` to produce the full set of rectification\nparameters. Results are exported as individual `.npy` files to\n`calib_result/`.\n\nA reprojection error below **0.5 px** indicates a good calibration.\n\n> **Distortion model:** the Edmund Optics #20-061 lens has 34.78% barrel\n> distortion at full field. The rational model (`cv2.CALIB_RATIONAL_MODEL`)\n> is used below, which fits an 8-coefficient distortion model instead of the\n> default 5. This better captures the heavy radial distortion of these\n> wide-angle lenses."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000010",
   "metadata": {},
   "outputs": [],
   "source": "print(\"Starting calibration — this may take a few minutes...\")\n\ncalib_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)\ncalib_flags = (cv2.CALIB_FIX_ASPECT_RATIO |\n               cv2.CALIB_ZERO_TANGENT_DIST |\n               cv2.CALIB_SAME_FOCAL_LENGTH |\n               cv2.CALIB_RATIONAL_MODEL)\n\n# Step 1: Stereo calibration.\nrms, cam_mat_l, dist_l, cam_mat_r, dist_r, R, T, E, F = cv2.stereoCalibrate(\n    object_points,\n    image_points_left,\n    image_points_right,\n    cameraMatrix1=None, distCoeffs1=None,\n    cameraMatrix2=None, distCoeffs2=None,\n    imageSize=image_size,\n    criteria=calib_criteria,\n    flags=calib_flags)\n\nprint(f\"RMS reprojection error: {rms:.4f} px\")\nprint(f\"Distortion coefficients: {dist_l.shape[1]} parameters (rational model)\")\nif rms > 0.5:\n    print(\"  Warning: error > 0.5 px — consider re-capturing images from more angles.\")\nelse:\n    print(\"  Error within acceptable range.\")\n\n# Step 2: Stereo rectification.\nR1, R2, P1, P2, Q, valid_roi_l, valid_roi_r = cv2.stereoRectify(\n    cam_mat_l, dist_l,\n    cam_mat_r, dist_r,\n    image_size, R, T,\n    flags=0)\n\n# Step 3: Compute undistortion + rectification maps.\nmap_l1, map_l2 = cv2.initUndistortRectifyMap(\n    cam_mat_l, dist_l, R1, P1, image_size, cv2.CV_32FC1)\nmap_r1, map_r2 = cv2.initUndistortRectifyMap(\n    cam_mat_r, dist_r, R2, P2, image_size, cv2.CV_32FC1)\n\n# Export all calibration results as .npy files (compatible with notebook 3).\nnp.save(os.path.join(calib_result_path, \"cam_mats_left.npy\"),           cam_mat_l)\nnp.save(os.path.join(calib_result_path, \"cam_mats_right.npy\"),          cam_mat_r)\nnp.save(os.path.join(calib_result_path, \"dist_coefs_left.npy\"),         dist_l)\nnp.save(os.path.join(calib_result_path, \"dist_coefs_right.npy\"),        dist_r)\nnp.save(os.path.join(calib_result_path, \"rot_mat.npy\"),                 R)\nnp.save(os.path.join(calib_result_path, \"trans_vec.npy\"),               T)\nnp.save(os.path.join(calib_result_path, \"e_mat.npy\"),                   E)\nnp.save(os.path.join(calib_result_path, \"f_mat.npy\"),                   F)\nnp.save(os.path.join(calib_result_path, \"rect_trans_left.npy\"),         R1)\nnp.save(os.path.join(calib_result_path, \"rect_trans_right.npy\"),        R2)\nnp.save(os.path.join(calib_result_path, \"proj_mats_left.npy\"),          P1)\nnp.save(os.path.join(calib_result_path, \"proj_mats_right.npy\"),         P2)\nnp.save(os.path.join(calib_result_path, \"disp_to_depth_mat.npy\"),       Q)\nnp.save(os.path.join(calib_result_path, \"valid_boxes_left.npy\"),        np.array(valid_roi_l))\nnp.save(os.path.join(calib_result_path, \"valid_boxes_right.npy\"),       np.array(valid_roi_r))\nnp.save(os.path.join(calib_result_path, \"undistortion_map_left.npy\"),   map_l1)\nnp.save(os.path.join(calib_result_path, \"undistortion_map_right.npy\"),  map_r1)\nnp.save(os.path.join(calib_result_path, \"rectification_map_left.npy\"),  map_l2)\nnp.save(os.path.join(calib_result_path, \"rectification_map_right.npy\"), map_r2)\n\nprint(f\"\\nCalibration exported to {calib_result_path}/ ({len(os.listdir(calib_result_path))} files)\")\nprint(f\"Baseline (||T||): {np.linalg.norm(T):.2f} {square_size and 'cm' or 'units'}\")"
  },
  {
   "cell_type": "markdown",
   "id": "b0000011",
   "metadata": {},
   "source": [
    "## Inspect rectified output\n",
    "\n",
    "Apply the rectification maps to the last image pair.\n",
    "Corresponding points should fall on the same horizontal scanline in both\n",
    "rectified images. If they don't, re-capture calibration images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000012",
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\nrect_left  = cv2.remap(img_left,  map_l1, map_l2, cv2.INTER_LINEAR)\nrect_right = cv2.remap(img_right, map_r1, map_r2, cv2.INTER_LINEAR)\n\nunrectified = np.hstack((\n    cv2.cvtColor(img_left,  cv2.COLOR_BGR2RGB),\n    cv2.cvtColor(img_right, cv2.COLOR_BGR2RGB),\n))\nrectified = np.hstack((\n    cv2.cvtColor(rect_left,  cv2.COLOR_BGR2RGB),\n    cv2.cvtColor(rect_right, cv2.COLOR_BGR2RGB),\n))\n\nfig, axes = plt.subplots(2, 1, figsize=(16, 12))\n\nfor ax, img, title in [\n    (axes[0], unrectified, \"Original stereo pair (left | right)\"),\n    (axes[1], rectified,   \"Rectified stereo pair (left | right)\"),\n]:\n    ax.imshow(img)\n    h = img.shape[0]\n    for y in range(0, h, h // 16):\n        ax.axhline(y=y, color=\"lime\", linewidth=0.5, alpha=0.6)\n    ax.set_title(title)\n    ax.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Open 3.Depthmap_with_Tuning_Bar.ipynb to continue.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agrippa-calibration",
   "language": "python",
   "name": "agrippa-calibration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}