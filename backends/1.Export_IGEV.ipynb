{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0000001",
   "metadata": {},
   "source": [
    "# 1. Export IGEV++ to ONNX\n",
    "\n",
    "Converts an IGEV++ PyTorch checkpoint to an ONNX model that can be loaded\n",
    "by `ag-cam-tools depth-preview --stereo-backend onnx`.\n",
    "\n",
    "The exported model expects two float32 inputs of shape `[1, 3, H, W]` in\n",
    "`[0, 255]` range and produces a float32 disparity map.\n",
    "\n",
    "**This export is tied to a specific resolution and max_disp.** If you\n",
    "recalibrate or change binning, re-run this notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. Clone the IGEV++ repository:\n",
    "   ```bash\n",
    "   git clone https://github.com/gangweiX/IGEV-plusplus.git ~/code/IGEV-plusplus\n",
    "   ```\n",
    "\n",
    "2. Download the SceneFlow checkpoint from the\n",
    "   [Google Drive folder](https://drive.google.com/drive/folders/1eubNsu03MlhUfTtrbtN7bfAsl39s2ywJ):\n",
    "   ```bash\n",
    "   mkdir -p ~/code/IGEV-plusplus/pretrained_models/igev_plusplus\n",
    "   pip install gdown\n",
    "   gdown --fuzzy \"https://drive.google.com/...\" \\\n",
    "       -O ~/code/IGEV-plusplus/pretrained_models/igev_plusplus/sceneflow.pth\n",
    "   ```\n",
    "\n",
    "3. Have a completed calibration session (from `ag-cam-tools calibration-capture`\n",
    "   + `2.Calibration.ipynb`).\n",
    "\n",
    "### Setup (one-time)\n",
    "```bash\n",
    "cd backends\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install -r requirements-onnx-export.txt\n",
    "python -m ipykernel install --user --name agrippa-export --display-name \"agrippa-export\"\n",
    "```\n",
    "\n",
    "Then select the **agrippa-export** kernel in Jupyter before running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000002",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0000003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements-onnx-export.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import json\n",
    "import os\n",
    "import struct\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000005",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set these paths to match your setup.  `calibration_session` should point\n",
    "to a calibrated session folder containing `calib_result/calibration_meta.json`\n",
    "and `calib_result/remap_left.bin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to cloned IGEV-plusplus repo root (contains core/igev_stereo.py).\n",
    "igev_src = os.path.expanduser(\"~/code/IGEV-plusplus\")\n",
    "\n",
    "# Path to pre-trained checkpoint.\n",
    "checkpoint_path = os.path.join(\n",
    "    igev_src, \"pretrained_models/igev_plusplus/sceneflow.pth\")\n",
    "\n",
    "# Calibration session folder.\n",
    "calibration_session = \"../calibration/calibration_20260225_160029_3cb907d2\"\n",
    "\n",
    "# GRU refinement iterations (12 is a good balance; upstream default is 16).\n",
    "iters = 12\n",
    "\n",
    "# Output ONNX file path.\n",
    "output_path = \"../models/igev_plusplus.onnx\"\n",
    "\n",
    "# Optional overrides (set to None to auto-detect from calibration).\n",
    "override_max_disp = None   # e.g. 192\n",
    "override_width    = None   # e.g. 720\n",
    "override_height   = None   # e.g. 540"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000007",
   "metadata": {},
   "source": [
    "## Load calibration metadata\n",
    "\n",
    "Reads `calibration_meta.json` to derive `max_disp` (cost volume size)\n",
    "and the remap table header to get the image dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000008",
   "metadata": {},
   "outputs": [],
   "source": "# --- Read max_disp from calibration_meta.json ---\nmeta_path = os.path.join(calibration_session, \"calib_result\",\n                         \"calibration_meta.json\")\nwith open(meta_path, \"r\") as f:\n    meta = json.load(f)\n\ndr = meta.get(\"disparity_range\", {})\nnum_disparities = dr.get(\"num_disparities\", 128)\n\n# IGEV++ builds a 3D cost volume with D = max_disp // 4 disparity levels.\n# patch0 (stride 2) and patch1 (stride 4) downsample D for the multi-scale\n# geometry volumes, and each is fed through a 3-level 3D hourglass that\n# halves D three times then doubles it back.  For the deconv skip\n# connections to align, every hourglass input D must be divisible by 8.\n#\n# With max_disp=256 → D=64:\n#   cost_agg0: D=48 (sliced)  → 48/8=6 ✓\n#   cost_agg1: patch0(64)→32  → 32/8=4 ✓\n#   cost_agg2: patch1(64)→16  → 16/8=2 ✓\nmax_disp = override_max_disp or max(num_disparities, 256)\n\nprint(f\"max_disp = {max_disp}  (calibration num_disparities = {num_disparities})\")\n\n# --- Read image dimensions from remap table header ---\n# Binary format: \"RMAP\" (4 bytes) + width(u32) + height(u32) + flags(u32)\nwidth = override_width\nheight = override_height\n\nif width is None or height is None:\n    remap_path = os.path.join(calibration_session, \"calib_result\",\n                              \"remap_left.bin\")\n    with open(remap_path, \"rb\") as f:\n        magic = f.read(4)\n        assert magic == b\"RMAP\", f\"Bad remap magic: {magic!r}\"\n        w, h, _flags = struct.unpack(\"<III\", f.read(12))\n        if width is None:\n            width = w\n        if height is None:\n            height = h\n\ndef pad_to_32(dim):\n    \"\"\"Round up to nearest multiple of 32.\"\"\"\n    return ((dim + 31) // 32) * 32\n\npad_w = pad_to_32(width)\npad_h = pad_to_32(height)\n\nprint(f\"Frame dimensions: {width}x{height}\")\nprint(f\"Padded (32-divisible): {pad_w}x{pad_h}\")"
  },
  {
   "cell_type": "markdown",
   "id": "a0000009",
   "metadata": {},
   "source": [
    "## Patch autocast for CPU tracing\n",
    "\n",
    "IGEV++ uses `torch.cuda.amp.autocast` in its forward pass, which breaks\n",
    "ONNX tracing on CPU-only machines.  We replace it with a no-op context\n",
    "manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0000010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched autocast for CPU tracing.\n"
     ]
    }
   ],
   "source": [
    "class _NoOpAutocast:\n",
    "    \"\"\"Drop-in replacement for torch.cuda.amp.autocast.\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        pass\n",
    "    def __call__(self, func):\n",
    "        return func\n",
    "\n",
    "if hasattr(torch.cuda, \"amp\"):\n",
    "    torch.cuda.amp.autocast = _NoOpAutocast\n",
    "\n",
    "if hasattr(torch, \"autocast\"):\n",
    "    _orig_autocast = torch.autocast\n",
    "    def _patched_autocast(device_type=\"cuda\", *args, **kwargs):\n",
    "        if device_type == \"cuda\":\n",
    "            return contextlib.nullcontext()\n",
    "        return _orig_autocast(device_type, *args, **kwargs)\n",
    "    torch.autocast = _patched_autocast\n",
    "\n",
    "print(\"Patched autocast for CPU tracing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000011",
   "metadata": {},
   "source": [
    "## Load IGEV++ model\n",
    "\n",
    "Imports the IGEV++ model from the cloned source, builds the configuration\n",
    "args it expects, and loads the pre-trained checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000012",
   "metadata": {},
   "outputs": [],
   "source": "# Add IGEV++ source to path.\nsys.path.insert(0, igev_src)\n\n# Try known import paths.\ntry:\n    from core.igev_stereo import IGEVStereo\n    print(f\"Imported IGEVStereo from core.igev_stereo\")\nexcept ImportError:\n    from igev_stereo import IGEVStereo\n    print(f\"Imported IGEVStereo from igev_stereo\")\n\n# Build args namespace that IGEV++ expects.\n#\n# The disparity range parameters control how many regression values each\n# multi-scale head produces:  disp_range / disp_interval == D for that head.\n# With max_disp=256 → cost volume D = 64:\n#   cost_agg0: slice first 48 of 64             → D=48 → s_disp_range/1 = 48 ✓\n#   cost_agg1: patch0 (stride 2) on first 64    → D=32 → m_disp_range/2 = 32 ✓\n#   cost_agg2: patch1 (stride 4) on all 64      → D=16 → l_disp_range/4 = 16 ✓\nclass ModelArgs:\n    pass\n\nargs = ModelArgs()\nargs.max_disp = max_disp\nargs.valid_iters = iters\nargs.mixed_precision = False\nargs.precision_dtype = \"float32\"\nargs.corr_implementation = \"reg\"\nargs.shared_backbone = False\nargs.corr_levels = 2\nargs.corr_radius = 4\nargs.n_downsample = 2\nargs.n_gru_layers = 3\nargs.slow_fast_gru = False\nargs.hidden_dims = [128] * 3\nargs.s_disp_range = 48\nargs.m_disp_range = 64\nargs.l_disp_range = 64\nargs.s_disp_interval = 1\nargs.m_disp_interval = 2\nargs.l_disp_interval = 4\n\nmodel = IGEVStereo(args)\nprint(f\"Model instantiated (max_disp={max_disp}, iters={iters})\")\n\n# Load checkpoint.\n# weights_only=False is required — the upstream checkpoint was saved with\n# older PyTorch and contains objects that the safe unpickler rejects.\nprint(f\"Loading checkpoint: {checkpoint_path}\")\nstate_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)\n\n# Handle DataParallel wrapper prefix.\nif any(k.startswith(\"module.\") for k in state_dict.keys()):\n    state_dict = {k.replace(\"module.\", \"\"): v\n                  for k, v in state_dict.items()}\n    print(\"Stripped 'module.' prefix from state_dict.\")\n\nmodel.load_state_dict(state_dict, strict=False)\nmodel.eval()\nprint(\"Checkpoint loaded.\")"
  },
  {
   "cell_type": "markdown",
   "id": "a0000013",
   "metadata": {},
   "source": [
    "## Export to ONNX\n",
    "\n",
    "Traces the model at the padded resolution with `torch.onnx.export` at\n",
    "opset 16.  The dummy inputs use `[0, 255]` float32 range (not `[0, 1]`)\n",
    "which matches what the C backend will send."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000014",
   "metadata": {},
   "outputs": [],
   "source": "# Ensure output directory exists.\nout_dir = os.path.dirname(output_path)\nif out_dir:\n    os.makedirs(out_dir, exist_ok=True)\n\n# IGEV++ expects [0, 255] float32 input.\nleft_dummy = torch.randn(1, 3, pad_h, pad_w) * 128.0 + 128.0\nright_dummy = torch.randn(1, 3, pad_h, pad_w) * 128.0 + 128.0\n\n# Set test_mode to get single output (final refinement only).\nmodel.test_mode = True\n\nprint(f\"Tracing with opset 16 at {pad_w}x{pad_h} (iters={iters})...\")\nt0 = time.time()\n\nwith torch.no_grad():\n    torch.onnx.export(\n        model,\n        (left_dummy, right_dummy),\n        output_path,\n        opset_version=16,\n        input_names=[\"left\", \"right\"],\n        output_names=[\"disparity\"],\n        dynamic_axes=None,  # fixed resolution for best performance\n        do_constant_folding=True,\n        dynamo=False,  # force legacy JIT-trace exporter (dynamo can't handle IGEV++)\n    )\n\ndt = time.time() - t0\nsize_mb = os.path.getsize(output_path) / (1024 * 1024)\nprint(f\"Raw ONNX exported in {dt:.1f}s ({size_mb:.1f} MB)\")"
  },
  {
   "cell_type": "markdown",
   "id": "a0000015",
   "metadata": {},
   "source": [
    "## Simplify with onnxsim\n",
    "\n",
    "Runs graph optimizations (constant folding, shape inference, dead-node\n",
    "elimination) to reduce model size and improve inference speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnxsim import simplify\n",
    "\n",
    "print(\"Simplifying with onnxsim...\")\n",
    "t0 = time.time()\n",
    "\n",
    "onnx_model = onnx.load(output_path)\n",
    "model_sim, check = simplify(onnx_model)\n",
    "\n",
    "if check:\n",
    "    onnx.save(model_sim, output_path)\n",
    "    dt = time.time() - t0\n",
    "    size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "    print(f\"Simplified in {dt:.1f}s ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"onnxsim check failed, keeping unsimplified model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000017",
   "metadata": {},
   "source": [
    "## Validate with ONNX Runtime\n",
    "\n",
    "Loads the exported model in ONNX Runtime and runs a single inference pass\n",
    "to verify the model is valid and produces reasonable output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "session = ort.InferenceSession(output_path,\n",
    "                               providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "inputs = session.get_inputs()\n",
    "outputs = session.get_outputs()\n",
    "print(f\"Inputs:  {[(i.name, i.shape, i.type) for i in inputs]}\")\n",
    "print(f\"Outputs: {[(o.name, o.shape, o.type) for o in outputs]}\")\n",
    "\n",
    "# Warm-up / validation inference.\n",
    "left = np.random.uniform(0, 255, (1, 3, pad_h, pad_w)).astype(np.float32)\n",
    "right = np.random.uniform(0, 255, (1, 3, pad_h, pad_w)).astype(np.float32)\n",
    "\n",
    "t0 = time.time()\n",
    "results = session.run(None, {inputs[0].name: left, inputs[1].name: right})\n",
    "dt = time.time() - t0\n",
    "\n",
    "disp = results[-1].squeeze()\n",
    "print(f\"\\nInference time: {dt:.2f}s\")\n",
    "print(f\"Output shape: {disp.shape}\")\n",
    "print(f\"Disparity range: [{disp.min():.2f}, {disp.max():.2f}]\")\n",
    "\n",
    "if disp.shape != (pad_h, pad_w):\n",
    "    print(f\"\\nWARNING: output shape {disp.shape} != expected ({pad_h}, {pad_w})\")\n",
    "else:\n",
    "    print(\"\\nValidation OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000019",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "The ONNX model has been exported, simplified, and validated.\n",
    "\n",
    "### Next steps\n",
    "\n",
    "1. Copy the model to your target machine:\n",
    "   ```bash\n",
    "   scp models/igev_plusplus.onnx jetson:~/agrippa-stereocam/models/\n",
    "   ```\n",
    "\n",
    "2. Run depth preview:\n",
    "   ```bash\n",
    "   ag-cam-tools depth-preview \\\n",
    "       --rectify calibration/calibration_YYYYMMDD_HHMMSS \\\n",
    "       --stereo-backend onnx \\\n",
    "       --model-path models/igev_plusplus.onnx\n",
    "   ```\n",
    "\n",
    "The C backend automatically selects the best execution provider\n",
    "(CUDA > CoreML > CPU) and handles padding/preprocessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agrippa-export",
   "language": "python",
   "name": "agrippa-export"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}