{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0000001",
   "metadata": {},
   "source": [
    "# 2. Export FoundationStereo to ONNX\n",
    "\n",
    "Converts a FoundationStereo PyTorch model to an ONNX model that can be\n",
    "loaded by `ag-cam-tools depth-preview --stereo-backend onnx`.\n",
    "\n",
    "The exported model expects two float32 inputs of shape `[1, 3, H, W]` and\n",
    "produces a float32 disparity map.\n",
    "\n",
    "**This export is tied to a specific resolution.** If you recalibrate or\n",
    "change binning, re-run this notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. Clone the FoundationStereo repository:\n",
    "   ```bash\n",
    "   git clone https://github.com/NVlabs/FoundationStereo.git ~/code/FoundationStereo\n",
    "   ```\n",
    "\n",
    "2. Download the pre-trained checkpoint (see the FoundationStereo README for links).\n",
    "\n",
    "3. Have a completed calibration session (from `ag-cam-tools calibration-capture`\n",
    "   + `2.Calibration.ipynb`).\n",
    "\n",
    "### Setup (one-time)\n",
    "```bash\n",
    "cd backends\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install torch torchvision onnx onnxsim onnxruntime numpy\n",
    "python -m ipykernel install --user --name agrippa-export --display-name \"agrippa-export\"\n",
    "```\n",
    "\n",
    "Then select the **agrippa-export** kernel in Jupyter before running.\n",
    "\n",
    "> **Note:** FoundationStereo may have additional dependencies (e.g. `timm`,\n",
    "> `einops`).  Install them as needed when the model import cell runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000002",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision onnx onnxsim onnxruntime numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import struct\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000005",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set these paths to match your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to cloned FoundationStereo repo root.\n",
    "foundation_src = os.path.expanduser(\"~/code/FoundationStereo\")\n",
    "\n",
    "# Path to pre-trained checkpoint.\n",
    "checkpoint_path = os.path.join(foundation_src, \"pretrained/model.pth\")\n",
    "\n",
    "# Calibration session folder.\n",
    "calibration_session = \"../calibration/calibration_YYYYMMDD_HHMMSS\"\n",
    "\n",
    "# Output ONNX file path.\n",
    "output_path = \"../models/foundation_stereo.onnx\"\n",
    "\n",
    "# Optional overrides (set to None to auto-detect from calibration).\n",
    "override_width  = None   # e.g. 720\n",
    "override_height = None   # e.g. 540"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000007",
   "metadata": {},
   "source": [
    "## Load calibration metadata\n",
    "\n",
    "Reads the remap table header to get the image dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = override_width\n",
    "height = override_height\n",
    "\n",
    "if width is None or height is None:\n",
    "    remap_path = os.path.join(calibration_session, \"calib_result\",\n",
    "                              \"remap_left.bin\")\n",
    "    with open(remap_path, \"rb\") as f:\n",
    "        header = f.read(8)\n",
    "        w, h = struct.unpack(\"<II\", header)\n",
    "        if width is None:\n",
    "            width = w\n",
    "        if height is None:\n",
    "            height = h\n",
    "\n",
    "def pad_to_32(dim):\n",
    "    \"\"\"Round up to nearest multiple of 32.\"\"\"\n",
    "    return ((dim + 31) // 32) * 32\n",
    "\n",
    "pad_w = pad_to_32(width)\n",
    "pad_h = pad_to_32(height)\n",
    "\n",
    "print(f\"Frame dimensions: {width}x{height}\")\n",
    "print(f\"Padded (32-divisible): {pad_w}x{pad_h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000009",
   "metadata": {},
   "source": [
    "## Load FoundationStereo model\n",
    "\n",
    "Imports the model from the cloned source and loads the checkpoint.\n",
    "\n",
    "> **Note:** FoundationStereo's import path and model API may vary between\n",
    "> versions.  Adapt the import and instantiation below to match the version\n",
    "> you cloned.  Check `README.md` in the FoundationStereo repo for the\n",
    "> correct usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add FoundationStereo source to path.\n",
    "sys.path.insert(0, foundation_src)\n",
    "\n",
    "# --- Adapt this block to match your FoundationStereo version ---\n",
    "# Common import patterns:\n",
    "#   from core.foundation_stereo import FoundationStereo\n",
    "#   from foundation_stereo import FoundationStereo\n",
    "# If the repo uses a config file, load it here too.\n",
    "\n",
    "try:\n",
    "    from core.foundation_stereo import FoundationStereo\n",
    "    print(\"Imported FoundationStereo from core.foundation_stereo\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        from foundation_stereo import FoundationStereo\n",
    "        print(\"Imported FoundationStereo from foundation_stereo\")\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            f\"Cannot import FoundationStereo from {foundation_src}. \"\n",
    "            f\"Check the repo structure and adapt the import above.\")\n",
    "\n",
    "# Load checkpoint.\n",
    "print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n",
    "\n",
    "# Handle DataParallel wrapper prefix.\n",
    "if any(k.startswith(\"module.\") for k in state_dict.keys()):\n",
    "    state_dict = {k.replace(\"module.\", \"\"): v\n",
    "                  for k, v in state_dict.items()}\n",
    "    print(\"Stripped 'module.' prefix from state_dict.\")\n",
    "\n",
    "# Instantiate and load weights.\n",
    "# Adapt constructor args to match your version.\n",
    "model = FoundationStereo()\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000011",
   "metadata": {},
   "source": [
    "## Export to ONNX\n",
    "\n",
    "Traces the model at the padded resolution.  FoundationStereo typically\n",
    "expects `[0, 1]` float32 input (unlike IGEV++ which uses `[0, 255]`).\n",
    "\n",
    "> **Important:** Check the FoundationStereo source for the expected input\n",
    "> range.  If the model expects `[0, 1]`, you will need to adjust the C\n",
    "> backend's preprocessing or include normalization in the ONNX graph.\n",
    "> The C backend (`stereo_onnx.c`) currently sends `[0, 255]` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists.\n",
    "out_dir = os.path.dirname(output_path)\n",
    "if out_dir:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Create dummy inputs.\n",
    "# Adjust the value range to match what FoundationStereo expects.\n",
    "left_dummy = torch.randn(1, 3, pad_h, pad_w) * 0.5 + 0.5   # [0, 1] range\n",
    "right_dummy = torch.randn(1, 3, pad_h, pad_w) * 0.5 + 0.5\n",
    "\n",
    "print(f\"Tracing with opset 16 at {pad_w}x{pad_h}...\")\n",
    "t0 = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        (left_dummy, right_dummy),\n",
    "        output_path,\n",
    "        opset_version=16,\n",
    "        input_names=[\"left\", \"right\"],\n",
    "        output_names=[\"disparity\"],\n",
    "        dynamic_axes=None,\n",
    "        do_constant_folding=True,\n",
    "    )\n",
    "\n",
    "dt = time.time() - t0\n",
    "size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "print(f\"Raw ONNX exported in {dt:.1f}s ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000013",
   "metadata": {},
   "source": [
    "## Simplify and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnxsim import simplify\n",
    "\n",
    "print(\"Simplifying with onnxsim...\")\n",
    "t0 = time.time()\n",
    "\n",
    "onnx_model = onnx.load(output_path)\n",
    "model_sim, check = simplify(onnx_model)\n",
    "\n",
    "if check:\n",
    "    onnx.save(model_sim, output_path)\n",
    "    dt = time.time() - t0\n",
    "    size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "    print(f\"Simplified in {dt:.1f}s ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"onnxsim check failed, keeping unsimplified model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "session = ort.InferenceSession(output_path,\n",
    "                               providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "inputs = session.get_inputs()\n",
    "outputs = session.get_outputs()\n",
    "print(f\"Inputs:  {[(i.name, i.shape, i.type) for i in inputs]}\")\n",
    "print(f\"Outputs: {[(o.name, o.shape, o.type) for o in outputs]}\")\n",
    "\n",
    "# Validation inference.\n",
    "left = np.random.uniform(0, 1, (1, 3, pad_h, pad_w)).astype(np.float32)\n",
    "right = np.random.uniform(0, 1, (1, 3, pad_h, pad_w)).astype(np.float32)\n",
    "\n",
    "t0 = time.time()\n",
    "results = session.run(None, {inputs[0].name: left, inputs[1].name: right})\n",
    "dt = time.time() - t0\n",
    "\n",
    "disp = results[-1].squeeze()\n",
    "print(f\"\\nInference time: {dt:.2f}s\")\n",
    "print(f\"Output shape: {disp.shape}\")\n",
    "print(f\"Disparity range: [{disp.min():.2f}, {disp.max():.2f}]\")\n",
    "\n",
    "if disp.shape != (pad_h, pad_w):\n",
    "    print(f\"\\nWARNING: output shape {disp.shape} != expected ({pad_h}, {pad_w})\")\n",
    "else:\n",
    "    print(\"\\nValidation OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0000016",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "The FoundationStereo ONNX model has been exported, simplified, and validated.\n",
    "\n",
    "### Input range note\n",
    "\n",
    "If FoundationStereo expects `[0, 1]` normalized input but the C backend\n",
    "sends `[0, 255]`, you have two options:\n",
    "\n",
    "1. **Prepend a division node to the ONNX graph** (recommended):\n",
    "   Add `input / 255.0` as the first operation so the model accepts\n",
    "   `[0, 255]` directly.  This can be done with `onnx.helper`.\n",
    "\n",
    "2. **Modify `stereo_onnx.c`** to divide by 255 during preprocessing.\n",
    "\n",
    "### Next steps\n",
    "\n",
    "1. Copy the model to your target machine:\n",
    "   ```bash\n",
    "   scp models/foundation_stereo.onnx jetson:~/agrippa-stereocam/models/\n",
    "   ```\n",
    "\n",
    "2. Run depth preview:\n",
    "   ```bash\n",
    "   ag-cam-tools depth-preview \\\n",
    "       --rectify calibration/calibration_YYYYMMDD_HHMMSS \\\n",
    "       --stereo-backend onnx \\\n",
    "       --model-path models/foundation_stereo.onnx\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agrippa-export",
   "language": "python",
   "name": "agrippa-export"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
